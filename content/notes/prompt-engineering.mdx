---
title: 'Prompt Engineering'
lastUpdated: '2021-05-13'
tags: ['LLMs', 'Programming', 'Productivity']
---

_This page contains various tips for prompt engineering/improving the
way you work with LLMs._

## Using LLMs well is often about reducing available information, not increasing it

GPT4 has been trained on most(?) of the internet. This means it has
access to huge amounts of information, most likely including the
information you are looking for. Consequently, the trick is often to
provide useful context to GPT not to add signal, but to filter out
noise.

Some ways you might achieve this:

- Ask for responses in a particular voice e.g. "How would [expert X]
  solve this?"
- Provide context about yourself and the domain in which your problem
  exists.

## Thread on Assorted Ways I Use LLMs for Programming

<blockquote class='twitter-tweet'>
  <p lang='en' dir='ltr'>
    0. Thread of ways I have used ChatGPT during day-to-day
    programming
  </p>
  &mdash; James (@mulholo) <a href='https://twitter.com/mulholo/status/1667147939393699840?ref_src=twsrc%5Etfw'>June 9, 2023</a>
</blockquote>

## See also

- [Lilian Weng's guide on prompt engineering](https://lilianweng.github.io/posts/2023-03-15-prompt-engineering/)
- [https://www.promptingguide.ai/](https://www.promptingguide.ai/)
